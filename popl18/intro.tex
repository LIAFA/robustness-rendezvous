%!TEX root = main.tex
\section{Introduction}

Communication with asynchronous message passing is widely used in parallel, concurrent, and distributed programs implementing various types of systems such as cache coherence protocols, communication protocols, protocols for distributed agreement, web applications, device drivers, etc. 
%
An asynchronous message passing program is built as a collection of processes running in parallel, communicating asynchronously by sending messages to each other via channels or message buffers. Messages sent to a given process are stored in its entry buffer, waiting for the moment they will be received by the process. In general, sending messages is not blocking for the sender process, which means that the message buffers are supposed to be of unbounded size. 

It is notorious that such programs are hard to get right. Indeed, asynchrony makes extremely difficult to apprehend the effect of all of their possible computations that result from intricate inter-leavings of action sequences performed by their different components. Even when the message buffers are bounded, the number of possible configurations that can be reached in such programs grows exponentially with respect to both their number of processes and the size of the message buffers, and of course when buffers are unbounded, the set of possibly reachable configurations is infinite. Due to this complexity, expressing and verifying properties such as invariants for such systems is extremely hard. In particular, when buffer are ordered (i.e., FIFO buffers), the verification of invariants (or dually of reachability queries) is undecidable in general, even when each of the processes is finite-state~\cite{DBLP:journals/jacm/BrandZ83}.

Therefore, an important issue is the design of verification approaches that avoid considering the full sets of computations and configurations to draw useful conclusions about the correctness of the considered programs. Several such approaches have been proposed including partial-order techniques, bounded analysis techniques, etc., e.g., \cite{DBLP:journals/tcs/BasuB16,DBLP:conf/oopsla/Desai0M14,DBLP:conf/tacas/BouajjaniE12,DBLP:conf/tacas/TorreMP08,DBLP:conf/popl/FlanaganG05}. Due to the hardness of the problem and its undecidability in general, these techniques have different limitations: either applicable only when buffers are bounded (e.g., partial-order techniques), or limited in scope, or do not provide any guarantees of termination or insight about completeness of the analysis.
% i.e., whether the performed analysis, although restricted, captures actually all possible behaviours in the system. 

In this paper, we propose a new approach for the analysis and verification of asynchronous message-passing programs that is applicable to systems with unbounded FIFO buffers, which provides a decision procedure for checking state reachability for a wide class of programs, and which is also applicable for bounded-analysis in the general case. 

The first issue we consider is to define a suitable concept for prioritizing the search that leads to an efficient verification approach and that is applicable to message-passing programs in general. Our starting intuition comes from our conviction that the behaviors of well designed systems can be seen as successions of {\em bounded interaction phases}, each of them being a sequence of send actions (by different processes), followed by a sequence of receive actions (again by different processes) corresponding to send actions belonging to the same interaction phase. For instance, interaction phases corresponding to {\em rendezvous communications} are formed of a single send action followed immediately by its corresponding receive action. More complex interactions are the result of exchanges of messages between processes. For instance two processes can send messages to each other, and therefore their interaction starts with two send actions (in any order), followed by the two corresponding receive actions (again in any order). This exchange schema can of course be generalized to any number of processes. Other, more complex interactions are also possible, for instance by combining several exchanges. We say that an interaction phase is {\em $k$-bounded}, for a given natural number $k > 0$, if its number of send actions is less than or equal to $k$. For instance rendezvous interactions are precisely 1-bounded phases.  In general, we call {\em $k$-exchange} any $k$-bounded interaction phase. 

Given $k > 0$, we consider that a computation is {\em $k$-synchronous} if it is a succession of $k$-exchanges.
% and we say that a computation is boundedly asynchronous if it is $k$-synchronous for some natural number $k > 0$.  
It can be seen that, in $k$-synchronous computations the sum of the sizes of all messages buffers is bounded by $k$. However, as it will be explained later, boundedness of the messages buffers does not guarantee that there is a $k$ such that all computations are $k$-synchronous. Indeed, there are sequences of actions that when they appear in a computation, they forbid the rearrangement of the computation into a sequence of exchanges.  

Then, we introduce a new bounded analysis for message passing programs called {\em exchange bounding analysis} (EBA). For a given $k$, this analysis corresponds to exploring the state space by considering only computations that are “equivalent” to $k$-synchronous computations. The equivalence relation we consider on computations is based on a notion of “trace” corresponding to a “happen-before” relation that captures the program order (the order in which actions occur in the code of a process) and the precedence order between send actions and their corresponding receive actions. Two computations are considered to be equivalent if they have the same trace, which means that they differ only in the order of causally independent actions. This analysis can be shown to be PSPACE-complete. 
%This reachability analysis is called $k$-bounded exchange analysis. 
%It can be used for checking reachability properties (violations of invariants), or the existence of deadlocks. 
%

An important feature of the bounding concept we define, is that it is possible to decide its completeness: For any given $k$, it is possible to decide whether every computation of the program (under the asynchronous semantics with unbounded message buffers) is equivalent to (i.e., has the same trace as) a $k$-synchronous computation of that program. 
In other words, we define a $k$-synchronous semantics for message passing programs allowing only $k$-synchronous computations, and we show that, for any given program $P$, the equality between the set of behaviours of $P$ under the asynchronous semantics and the set of its behaviours under the $k$-synchronous semantics, is decidable. When this equality holds, we say that the program is {\em $k$-synchronizable}. Knowing that a program is $k$-synchronizable allows to conclude that an invariant holds for all computations of the program if no invariant violations have been found by its $k$-bounded exchange analysis. Notice that $k$-synchronizability of a program {\em does not} imply that all its behaviours use bounded buffers. It only means that for every computation of the program there exists another computation of the program that has the same trace and that is $k$-synchronous (and therefore, that does not need to store more than $k$ messages in the buffers). Consider for instance a program with two processes, a producer that consists of a loop of sends, and a consumer that consists of a loop of receives. Although there are computations with arbitrarily large configurations of the entry buffer of the consumer, the program is 1-synchronous because all its computations are equivalent to the computation where each message sent by the producer is immediately received by the consumer. 
%(i.e., that is a succession of $k$-bounded interaction phases). 

Importantly, we show that checking $k$-synchronizability of a program can itself be done by considering {\em only} $k$-synchronous computations (of a slightly different program), i.e., we do not need to consider all computations of the program for checking that they are all equivalent to $k$-synchronous ones. In fact, we provide a linear reduction of the problem of checking $k$-synchronizability to the state reachability under the $k$-synchronous semantics. The idea is that only a class of $k$-synchronizability violations need to be considered, and these violations correspond to computations containing a cycle in a suitably defined {\em conflict graph} associated with the considered computation. In this graph, the nodes are matching pairs of send and receive actions (i.e., a send action and its corresponding receive action), and edges between such pairs correspond to program order constraints between actions of these pairs. We show that the detection of such cycles can be done by considering the $k$-synchronous semantics, using a program instrumentation that adds $k + N$ boolean variables to the program, where $N$ is the number of processes in the program. This instrumentation allows to check (basically by delaying one send action, and checking later that there is a matching receive action) that the $k+1$-synchronous semantics (when applied to the considered computation) is able to generate a cycle of size $k+1$ in the conflict graph. For instance, consider an exchange $send (p, q, m_1), send (q, p, m_2), receive (q, m_1), receive (p, m_2)$. The conflict graph has two nodes $n_1 = [ send(p, q, m_1), receive (q, m_1) ]$ and $n_2 = [ send(q, p, m_2), receive (p, m_2) ]$, and due to program constraints, there is an edge from $n_1$ to $n_2$ since $send(p, q, m_1)$ is before $receive (p, m_2)$ as well as an edge from $n_2$ to $n_1$ since $send(q, p, m_2)$ is before $receive (q, m_1)$. Therefore, this computation is not 1-synchronizable, i.e., it is not equivalent to a computation using rendezvous communications. 
Due to the reduction described above, the problem of checking $k$-synchronizability of a message passing program with unbounded buffers is PSPACE-complete, i.e., not harder than checking state reachability in synchronous programs. Therefore, for $k$-synchronizable programs, it is possible to decide invariant properties without considering unbounded message buffers, and the overall complexity in this case is PSPACE. 

Then, a method for verifying asynchronous message passing programs can be defined, 
%Then, as usual, defining a parametrised bounded analysis concept leads to an iterative method for verifying programs 
based on iterating $k$-bounded analyses with increasing value of $k$, starting from $k=1$. If for some $k$, a violation (i.e., reachability of an error state) is detected, then the iteration stops and the conclusion is that the program is not correct. On the other hand, if for some $k$, the program is shown to be $k$-synchronizable and no violations have been found, then again the iteration terminates and the conclusion is that the program is correct. 

However, it might be the case that the program is {\em not} synchronizable for any $k$ (we will discuss later when this can happen). In this case, if the program is correct then the iteration above will not terminate. Therefore, an important issue is to determine whether {\em there exists a $k$ such that the program is $k$-synchronizable}. This problem of checking synchronizability is hard, and we believe that it is undecidable, but for the time being we do not have a formal proof about this fact. However, we are able to define a significant class of programs, including most examples we have seen in practice, for which this problem is decidable.  The important fact is that non-synchronizability is due precisely to two reasons. One reason is that mutually interacting processes have among them one process that can execute an unbounded loop of receive actions before any subsequent send action, or a process that can perform a receive action preceded by an unbounded loop of sends. 
%the existence of unbounded exchange phases between processes where each process has a loop of send actions to mutually interacting other processes (before any receive action). 
A second reason is due to the presence of interactions where exchanges are overlapping with other interactions where sends and receives are alternating (it suffices to have one alternation). This forbids finding a rearrangement of the computation into a succession of exchanges (regardless of their boundedness). Roughly speaking, the occurrence of this “bad pattern” characterizes the fact that overlapping exchanges are not serializable. 

%Then our approach is as follows: 
First, we show that the detection of this “bad pattern” in $k$-synchronous computations is possible again by a linear reduction to a state reachability problem in synchronous programs. Therefore, if the pattern is found for some $k$, we know that the program is definitely not synchronizable. 

Furthermore, we consider a syntactically defined class of programs, called {\em flow-bounded programs}, for which the first source of non-synchronizability is  discarded. A program is {\em flow-bounded} if in all of its components, there is no unbounded loop with only receive actions and no unbounded loop of only send actions from which there is a path to a receive action. For this class of programs, it can be shown that a program is not synchronizable if and only if the “bad pattern” mentioned before occurs in some computation of the program (under the asynchronous semantics). Therefore, the problem of checking if there is a $k$ for which a flow-bounded program is $k$-synchronizable is decidable: Either the program is synchronizable and in this case there must be a $k$ for which it is $k$-synchronizable, or it is not synchronizable, and in this case there must be a $k$ for which the “bad pattern” is reachable by $k$-synchronous computations. Notice that it may happen that programs are synchronizable even though they are not flow-bounded (i.e., flow-boundedness is a sufficient condition for deciding synchronizability, but it does imply non-synchronizability). For instance, the producer-consumer program mentioned earlier in this section is clearly not flow-bounded but it is 1-synchronous. 

We have now all the ingredients that are used in defining our method for verifying state reachability in asynchronous message passing programs: 
%Overall, our state reachability verification approach for asynchronous programs can be summarised as follows: 
\begin{enumerate}
\item
If the program is flow-bounded, and if it is synchronizable (which is decidable in this case), then checking state reachability is decidable and can be done by considering only $k$-synchronous computations, for increasing values of $k$. 
\item 
If the program is not flow-bounded, then it is always possible to use our parametrized under-approximate analysis for arbitrarily high, fixed values of $k$. As we said earlier, the program can still be synchronizable for some $k$ (even if it is outside the syntactical class for which we have a decision procedure). So, at each step, $k$-synchronizability (which is decidable for all asynchronous programs) is checked, and if the answer is YES, then the search stops and the answer to the state reachability query is NO. If the answer to $k$-synchronizability is NO, then the procedure should be repeated for $k+1$ (or stopped by reporting absence of violations up to $k$).  
\end{enumerate}

Finally, we show that all the techniques we develop in this paper can also be used for verifying the existence of deadlocks. To summarize, the contributions of this paper are the following:

\begin{itemize}
\item A new bounded analysis for message passing programs called Exchange Bounded Analysis. This analysis is based on exploring $k$-synchronous computations. The complexity of state reachability under EBA is PSPACE-complete. 

\item A procedure for deciding $k$-synchronizability of asynchronous message passing programs. The procedure never considers the asynchronous semantics, and it is based on a exchange bounded analysis of an instrumented version of the original program. Consequently, the state reachability problem is decidable for $k$-synchronizable programs. Deciding  $k$-synchronizability and state reachability in this case is PSPACE-complete. 

\item A procedure for deciding synchronizability for a class of message passing programs called flow-bounded programs. The procedure again uses an exchange bounded analysis of an instrumented version of the program. Consequently, the state reachability problem is decidable for synchronizable flow-bounded programs. 
%Deciding  synchronizability and state reachability in this case is PSPACE-complete. 

\item The results above are also applicable to verifying the existence of deadlocks. 

\end{itemize}
