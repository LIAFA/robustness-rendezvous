%!TEX root = main.tex
\section{Introduction}

Communication with asynchronous message passing is widely used in parallel, concurrent, and distributed programs implementing various types of systems such as cache coherence protocols, communication protocols, protocols for distributed agreement, web applications, device drivers, etc. 
%
An asynchronous message passing program is built as a collection of processes running in parallel, communicating asynchronously by sending messages to each other via channels or message buffers. Messages sent to a given process are stored in its entry buffer, waiting for the moment they will be received by the process. In general, sending messages is not blocking for the sender process, which means that the message buffers are supposed to be of unbounded size. 

It is notorious that such programs are hard to get right. Indeed, asynchrony makes extremely difficult to apprehend the effect of all of their possible computations that result from intricate inter-leavings of action sequences performed by their different components. Even when the message buffers are bounded, the number of possible configurations that can be reached in such programs grows exponentially with respect to both their number of processes and the size of the message buffers, and of course when buffers are unbounded, the set of possibly reachable configurations is infinite. Due to this complexity, expressing and verifying properties such as invariants for such systems is extremely hard. In particular, when buffers are ordered (i.e., FIFO buffers), the verification of invariants (or dually of reachability queries) is undecidable in general, even when each of the processes is finite-state.

Therefore, an important issue is the design of verification approaches that avoid considering the full sets of computations and configurations to draw useful conclusions about the correctness of the considered programs. Several such approaches have been proposed including partial-order techniques, bounded analysis techniques, etc. \cite{}. Due to the hardness of the problem and its undecidability in general, these techniques have different limitations: either applicable only when buffers are bounded (e.g., partial-order techniques), or limited in scope, or do not provide any guarantees of termination or insight about completeness of the analysis.
% i.e., whether the performed analysis, although restricted, captures actually all possible behaviours in the system. 

In this paper, we propose a new approach for the analysis and verification of asynchronous message-passing programs that is applicable to systems with unbounded FIFO buffers, which provides a decision procedure for checking state reachability for a wide class of programs, and which is also applicable for bounded-analysis in the general case. 

The first issue we consider is to define a suitable concept for prioritizing the search that leads to an efficient verification approach and that is applicable to message-passing programs in general. Our starting intuition comes from our conviction that the behaviors of well designed systems can be seen as successions of bounded interaction phases, each of them being a sequence of send operations (by different processes), followed by a sequence of receive operations (again by different processes) corresponding to send operations belonging to the same interaction phase. For instance, interaction phases corresponding to rendezvous communication are formed by a single send operation followed immediately by its corresponding receive operation. More complex interactions are the result of exchanges of messages between processes. For instance two processes can send messages to each other, and therefore their interaction starts with two send operations (in any order), followed by the two corresponding receive operations (again in any order). This exchange schema can of course be generalized to any number of processes. Other, more complex interactions are also possible, for instance by combining several exchanges. We say that an interaction phase is $k$-bounded, for a given natural number $k > 0$, if its number of send operations is less or equal to $k$. For instance rendezvous interactions are precisely 1-bounded phases.  In general, we call $k$-exchange any $k$-bounded interaction phase. 

Given $k > 0$, we consider that a computation is $k$-synchronous if it is a succession of $k$-exchanges.
% and we say that a computation is boundedly asynchronous if it is $k$-synchronous for some natural number $k > 0$.  
It can be seen that, in $k$-synchronous computations the sum of the sizes of all messages buffers is bounded by $k$. However, as we will explain later, boundedness of the messages buffers does not guarantee that there is a $k$ such that all computations are $k$-synchronous.

Then, we introduce a new bounded analysis for message passing programs called exchange bounding analysis (EBA). For a given $k$, this analysis corresponds to checking state reachability by considering only computations that are “equivalent” to $k$-synchronous computations. The equivalence relation we consider on computations is based on a notion of “trace” that corresponds to a “happen-before” relation capturing the program order (the order in which operations occur in the code of each single process) and the precedence order between send operations and their corresponding receive operations. Two computations are considered to be equivalent if they have the same trace, which means that they differ only in the order of causally independent actions. This analysis can be shown to be PSPACE-complete. 
%This reachability analysis is called $k$-bounded exchange analysis. 
%It can be used for checking reachability properties (violations of invariants), or the existence of deadlocks. 
%

The important feature of the bounding concept we define, is that it is possible to decide its completeness: For any given $k$, it is possible to decide whether every computation of the program (under the asynchronous semantics with unbounded message buffers) is equivalent to a $k$-synchronous computation of that program. 
In other words, we define a $k$-synchronous semantics for message passing programs allowing only $k$-synchronous computations, and we show that, for any given program $P$, the equality between the set of behaviors of $P$ under the asynchronous semantics and the set of its behaviors under the $k$-synchronous semantics, is decidable. When this equality holds, we say that the program is $k$-synchronizable. Knowing that a program is $k$-synchronizable allows to conclude that an invariant holds for all computations of the program if no invariant violations have been found by its $k$-bounded exchange analysis. Notice that $k$-synchronizability of a program does not imply that all its behaviors use bounded buffers. It means only that for every computation of the program there exists another computation of that program that has the same trace and that is $k$-synchronous (and therefore, that does not need to store in  buffers more than $k$ messages). Consider for instance a program with two processes, a producer that consists of a loop of sends, and a consumer that consists of a loop of receives. Although there are computations with arbitrarily large configurations of the entry buffer of the consumer, the program is 1-synchronous because all its computations are equivalent to the computation where each sent message is immediately received. 
%(i.e., that is a succession of $k$-bounded interaction phases). 



Importantly, we show that checking $k$-synchronizability of a program can be done by considering only $k$-synchronous computations (of an instrumented program), i.e., we do not need to consider all asynchronous  computations. In fact, we provide a linear reduction of the problem of checking $k$-synchronizability to the state reachability under the $k$-synchronous semantics. The idea is that violations of $k$-synchronizability contain a cycle of size $k+1$ in a suitably defined conflict graph, where nodes are matching pairs of send and receive operations, and edges between such pairs correspond to program order constraints between elements of these pairs. We show that the detection of such cycles can be done by considering the $k$-synchronous semantics, using a program instrumentation that adds $k$ boolean variables to the program, and $N$ more boolean variables when $k>2$, where $N$ is the number of processes in the program. In fact, we show that the problem of checking $k$-synchronizability of an asynchronous message passing program with unbounded buffers is PSPACE-complete, i.e., not harder than state reachability in synchronous programs. Therefore, for $k$-synchronizable programs, it is possible to decide invariant properties without considering unbounded message buffers, and the overall complexity in this case is PSPACE. 

Then, a method for verifying asynchronous message passing programs can be defined, 
%Then, as usual, defining a parametrised bounded analysis concept leads to an iterative method for verifying programs 
based on iterating $k$-bounded analyses with increasing values of $k$, starting from $k=1$. If for some $k$, a violation (i.e., reachability of an error state) is detected, then the iteration stops and the conclusion is that the program is not correct. On the other hand, if for some $k$, the program is shown to be $k$-synchronizable and no violations have been found, then again the iteration terminates and the conclusion is that the program is correct. 

However, it might be the case that the program is not synchronizable for any $k$. (We will see later the reasons of that.) In this case, if the program is correct then the iteration above will not terminate. Therefore, an important issue is to determine whether {\em there exists a $k$ such that the program is $k$-synchronizable}. This problem is hard, and we believe it is undecidable, but for the time being we do not have a formal proof about this fact. However, we define a significant class of programs, including all examples we have seen in practice, for which this problem is decidable.  The important fact is that non-synchronizability is due precisely to two reasons. One reason is that mutually interacting processes have among them one process that can execute an unbounded loop of receive operations before any subsequent send operation. 
%the existence of unbounded exchange phases between processes where each process has a loop of send operations to mutually interacting other processes (before any receive operation). 
A second reason is due to the presence of interactions where exchanges are overlapping with other interaction schemas where sends and receives are alternating (it suffices to have one alternation). This forbids finding a rearrangement of the computation into a succession of interaction phases. Roughly speaking, the occurrence of this “bad pattern” characterizes the fact that exchange phases are not serializable. 

%Then our approach is as follows: 
First, we show that the detection of this “bad pattern” in $k$-synchronous computations is possible again by a linear reduction to a state reachability problem in synchronous programs. Therefore, if the pattern is found for some $k$, we know that the program is definitely not synchronizable. 

Furthermore, we consider a syntactically defined class of programs, called {\em receive-bounded programs}, for which the first source of non-synchronizability is  discarded. A program is {\em receive-bounded} if in all of its components, there is no unbounded loop with only receive operations. For this class of programs, it can be shown that a program is not synchronizable if and only if the “bad pattern” mentioned before occurs in some computation of the program (under the asynchronous semantics). Therefore, the problem of checking if there is a $k$ for which a receive-bounded program is $k$-synchronizable is decidable: Either the program is synchronizable and in this case there must be a $k$ for which it is $k$-synchronizable, or it is not synchronizable, and in this case there must be a $k$ for which the “bad pattern” is reachable by $k$-synchronous computations. Notice that programs which are not receive-bounded can be synchronizable. For instance, the producer-consumer program mentioned above is clearly not receive-bounded but 1-synchronous. 

We have now all the ingredients that are used in defining our method for verifying state reachability in asynchronous message passing programs: 
%Overall, our state reachability verification approach for asynchronous programs can be summarised as follows: 
\begin{enumerate}
\item
If the program is receive-bounded, and if it is synchronizable (which is decidable in this case), then checking state reachability is decidable and can be done by considering only $k$-synchronous computations, for increasing values of $k$. 
\item 
If the program is not receive-bounded, then it is always possible to use our parametrized under-approximate analysis for arbitrarily high, fixed values of $k$. As we said earlier, the program can still be synchronizable for some $k$ (even if it is outside the syntactical class for which we have a decision procedure). So, at each step, $k$-synchronizability (which is decidable for all asynchronous programs) is checked, and if the answer is YES, then the search stops and the answer to the state reachability query is NO. If the answer to $k$-synchronizability is NO, then the procedure should be repeated for $k+1$ (or stopped by reporting absence of violations up to $k$).  
\end{enumerate}

To summarize, the contributions of this paper are the following:

\begin{itemize}
\item A new bounded analysis for message passing programs called Exchange Bounded Analysis. This analysis is based on exploring $k$-synchronous computations. 

\item A procedure for deciding $k$-synchronizability of asynchronous message passing programs. The procedure doesn't consider the asynchronous semantics, and it is based on an exchange bounded analysis of an instrumented version of the original program. Consequently, the state reachability problem is decidable for $k$-synchronizable programs. 

\item A procedure for deciding synchronizability for a class of message passing programs called receive-bounded programs. The procedure again uses an exchange bounded analysis of an instrumented version of the program. Consequently, the state reachability problem is decidable for synchronizable receive-bounded programs. 

\end{itemize}
